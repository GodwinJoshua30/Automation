{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb5a6f2",
   "metadata": {},
   "source": [
    "# Automation in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87cfa5",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a353cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import isnan\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f296d8",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4137525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValues:\n",
    "    # Function for handling missing values in the data\n",
    "    def handle(df, missing_num='auto', missing_categ='auto', _n_neighbors=3):\n",
    "        count_missing = df.isna().sum().sum()\n",
    "        if count_missing != 0:\n",
    "            # drop rows containing only missing values\n",
    "            df = df.dropna(how='all')\n",
    "            df.reset_index(drop=True)\n",
    "            \n",
    "            if self.missing_num:\n",
    "                # automated handling of numerical missing values\n",
    "                if missing_num == 'auto':\n",
    "                    missing_num = 'linreg'\n",
    "                    lr = LinearRegression()\n",
    "                    df = MissingValues._lin_regression_impute(self, df, lr)\n",
    "                    missing_num = 'knn'\n",
    "                    imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
    "                    df = MissingValues._impute(self, df, imputer, type='num')\n",
    "                # linear regression imputation\n",
    "                elif missing_num == 'linreg':\n",
    "                    lr = LinearRegression()\n",
    "                    df = MissingValues._lin_regression_impute(self, df, lr)\n",
    "                # knn imputation\n",
    "                elif missing_num == 'knn':\n",
    "                    imputer = KNNImputer(n_neighbors=_n_neighbors)\n",
    "                    df = MissingValues._impute(self, df, imputer, type='num')\n",
    "                # mean, median or mode imputation\n",
    "                elif missing_num in ['mean', 'median', 'most_frequent']:\n",
    "                    imputer = SimpleImputer(strategy=self.missing_num)\n",
    "                    df = MissingValues._impute_missing(self, df, imputer, type='num')\n",
    "                # delete missing values\n",
    "                elif missing_num == 'delete':\n",
    "                    df = MissingValues._delete(self, df, type='num')\n",
    "                   \n",
    "            if missing_categ:\n",
    "                ...\n",
    "        else:\n",
    "            pass\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae0fc4",
   "metadata": {},
   "source": [
    "# outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ce7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outliers:\n",
    "    # Function that handles outliers in the data\n",
    "    def handle(df, outliers='winz'):\n",
    "        if outliers:\n",
    "            if outliers == 'winz':  \n",
    "                df = Outliers._winsorization(self, df)\n",
    "            elif ourliers == 'delete':\n",
    "                df = Outliers._delete(self, df)\n",
    "        return df     \n",
    "    def _winsorization(df):\n",
    "        ...\n",
    "    def _delete(df):\n",
    "        ...\n",
    "    def _compute_bounds(df, feature):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39fb75",
   "metadata": {},
   "source": [
    "# categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49125ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeCateg:\n",
    "    # Function for encoding of categorical features\n",
    "    # to specify columns set encode_categ to: ['auto', ['col1', col2']]\n",
    "    def handle(df, encode_categ=['auto']):\n",
    "        if encode_categ[0]:\n",
    "            # select non numeric features\n",
    "            cols_categ = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns)\n",
    "            # check if all columns should be encoded\n",
    "            if len(encode_categ) == 1:\n",
    "                target_cols = cols_categ # encode ALL columns\n",
    "            else:\n",
    "                target_cols = encode_categ[1] # encode only specific columns\n",
    "            for feature in target_cols:\n",
    "                if feature in cols_categ:\n",
    "                    feature = feature # columns are column names\n",
    "                else:\n",
    "                    feature = df.columns[feature] # columns are indexes\n",
    "                try:\n",
    "                    # skip encoding of datetime features\n",
    "                    pd.to_datetime(df[feature])\n",
    "                except:\n",
    "                    try:\n",
    "                        if encode_categ[0] == 'auto':\n",
    "                            # ONEHOT encode if not more than 10 unique values to encode\n",
    "                            if df[feature].nunique() <=10:\n",
    "                                df = EncodeCateg._to_onehot(df, feature)\n",
    "                            # LABEL encode if not more than 20 unique values to encode\n",
    "                            elif df[feature].nunique() <=20:\n",
    "                                df = EncodeCateg._to_label(df, feature)\n",
    "                            # skip encoding if more than 20 unique values to encode\n",
    "                        elif encode_categ[0] == 'onehot':\n",
    "                            df = EncodeCateg._to_onehot(df, feature)\n",
    "                        elif encode_categ[0] == 'label':\n",
    "                            df = EncodeCateg._to_label(df, feature)\n",
    "                    except:\n",
    "                        pass\n",
    "        return df\n",
    "    def _to_onehot(df, feature, limit=10):\n",
    "        ...\n",
    "    def _to_label(df, feature):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59325abf",
   "metadata": {},
   "source": [
    "# extraction of datetime features in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd389ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature for extracting datetime values\n",
    "def convert_datetime(df, extract_datetime='s'):\n",
    "    cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns) \n",
    "    for feature in cols: \n",
    "        try:\n",
    "            # convert features encoded as strings to type datetime ['D','M','Y','h','m','s']\n",
    "            df[feature] = pd.to_datetime(df[feature], infer_datetime_format=True)\n",
    "            df['Day'] = pd.to_datetime(df[feature]).dt.day\n",
    "            if extract_datetime in ['M','Y','h','m','s']:\n",
    "                df['Month'] = pd.to_datetime(df[feature]).dt.month\n",
    "                if extract_datetime in ['Y','h','m','s']:\n",
    "                    df['Year'] = pd.to_datetime(df[feature]).dt.year\n",
    "                    if extract_datetime in ['h','m','s']:\n",
    "                        df['Hour'] = pd.to_datetime(df[feature]).dt.hour\n",
    "                        if extract_datetime in ['m','s']:\n",
    "                            df['Minute'] = pd.to_datetime(df[feature]).dt.minute\n",
    "                            if extract_datetime in ['s']:\n",
    "                              df['Sec'] = pd.to_datetime(df[feature]).dt.second\n",
    "            try: # check if entries for the extracted dates/times are valid, otherwise drop\n",
    "                if (df['Hour'] == 0).all() and (df['Minute'] == 0).all() and (df['Sec'] == 0).all():\n",
    "                    df.drop('Hour', inplace = True, axis =1 )\n",
    "                    df.drop('Minute', inplace = True, axis =1 )\n",
    "                    df.drop('Sec', inplace = True, axis =1 )\n",
    "                elif (df['Day'] == 0).all() and (df['Month'] == 0).all() and (df['Year'] == 0).all():\n",
    "                    df.drop('Day', inplace = True, axis =1 )\n",
    "                    df.drop('Month', inplace = True, axis =1 )\n",
    "                    df.drop('Year', inplace = True, axis =1 )  \n",
    "            except:\n",
    "                pass\n",
    "        except: # feature cannot be converted to datetime\n",
    "            pass          \n",
    "return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
